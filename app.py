import streamlit as st
import google.generativeai as genai
from github import Github
import json
import uuid

# ================= 1. åŸºç¡€é…ç½® & å¼ºåŠ› CSS æ³¨å…¥ =================
st.set_page_config(page_title="Lee's AI Studio", page_icon="ğŸ’ ", layout="wide")

# æ³¨å…¥ CSSï¼šè¿™æ˜¯æ”¹å˜æ°”è´¨çš„å…³é”®
st.markdown("""
<style>
    /* 1. å…¨å±€å­—ä½“å‹ç¼©ï¼šå¼ºåˆ¶ 14pxï¼Œè¡Œé«˜ç´§å‡‘ */
    html, body, [class*="css"] {
        font-family: 'Roboto', 'Inter', sans-serif;
        font-size: 14px !important;
        line-height: 1.5 !important;
    }
    
    /* 2. éšè— Streamlit è‡ªå¸¦çš„çº¢æ¡ã€èœå•ã€é¡µè„š */
    header {visibility: hidden;}
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* 3. ä¾§è¾¹æ ä¼˜åŒ–ï¼šå»è¾¹æ¡†ï¼Œæç®€ */
    section[data-testid="stSidebar"] {
        width: 260px !important; # å˜çª„ä¸€ç‚¹
        border-right: 1px solid #E5E7EB;
    }
    
    /* 4. æŒ‰é’®æ ·å¼ï¼šGoogle é£æ ¼çš„åœ†è§’å’Œè“è‰²æ–‡å­— */
    div.stButton > button {
        background-color: transparent;
        border: 1px solid #DADCE0;
        color: #3C4043;
        border-radius: 4px;
        font-size: 13px;
        padding: 4px 12px;
        height: auto;
    }
    div.stButton > button:hover {
        border-color: #1A73E8;
        color: #1A73E8;
        background-color: #F1F3F4;
    }
    /* ä¸»æŒ‰é’®å®å¿ƒè“ */
    div.stButton > button[kind="primary"] {
        background-color: #1A73E8;
        color: white;
        border: none;
    }

    /* 5. èŠå¤©æ°”æ³¡å»è‰²å»æ¡†ï¼šåƒ AI Studio ä¸€æ ·æ²‰æµ¸ */
    .stChatMessage {
        background-color: transparent !important;
        border: none !important;
        padding: 5px 0px !important;
    }
    /* ç”¨æˆ·å¤´åƒèƒŒæ™¯ */
    div[data-testid="stChatMessageAvatarUser"] {
        background-color: #E8EAED !important;
    }
    /* AI å¤´åƒèƒŒæ™¯ */
    div[data-testid="stChatMessageAvatarAssistant"] {
        background-color: #E8F0FE !important;
    }

    /* 6. è¾“å…¥æ¡†ä¼˜åŒ– */
    .stChatInputContainer {
        border-radius: 8px !important;
        border-color: #DADCE0 !important;
    }
    
    /* 7. æ ‡é¢˜å­—å·å‹åˆ¶ */
    h1 { font-size: 18px !important; color: #202124; margin-bottom: 0px;}
    h2 { font-size: 16px !important; color: #202124; }
    h3 { font-size: 14px !important; font-weight: 600; }
    
    /* 8. å»æ‰é¡¶éƒ¨ç©ºç™½ */
    .block-container {
        padding-top: 2rem !important;
        padding-bottom: 2rem !important;
    }
</style>
""", unsafe_allow_html=True)

# è¯»å–å¯†é’¥
api_key = st.secrets.get("GEMINI_API_KEY")
github_token = st.secrets.get("GITHUB_TOKEN")
repo_name = st.secrets.get("REPO_NAME")

if not api_key or not github_token or not repo_name:
    st.error("âš ï¸ ç¼ºå°‘å¯†é’¥")
    st.stop()

genai.configure(api_key=api_key)

# ================= 2. æ ¸å¿ƒé€»è¾‘ =================

@st.cache_data(ttl=3600)
def get_available_models():
    try:
        model_list = []
        priority_models = ["gemini-2.0-flash-thinking-exp-1219", "gemini-1.5-pro", "gemini-2.0-flash-exp"]
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods and "gemini" in m.name:
                clean_name = m.name.replace("models/", "")
                if clean_name not in priority_models:
                    model_list.append(clean_name)
        return priority_models + sorted(model_list, reverse=True)
    except:
        return ["gemini-1.5-pro"]

def load_data(filename):
    try:
        g = Github(github_token)
        repo = g.get_repo(repo_name)
        try:
            contents = repo.get_contents(filename)
            return json.loads(contents.decoded_content.decode()), contents.sha
        except:
            return {}, None
    except:
        return {}, None

def save_data(filename, data, sha, message="Update"):
    try:
        g = Github(github_token)
        repo = g.get_repo(repo_name)
        content_str = json.dumps(data, indent=2, ensure_ascii=False)
        if sha:
            repo.update_file(filename, message, content_str, sha)
        else:
            repo.create_file(filename, "Init", content_str)
        return True
    except:
        return False

# ================= 3. æç®€ç•Œé¢ =================

if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = None

roles_data, roles_sha = load_data("roles.json")
chats_data, chats_sha = load_data("chats.json")
available_models = get_available_models()

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.markdown("### Lee's AI Studio")
    
    if st.button("ï¼‹ New Chat", type="primary", use_container_width=True):
        st.session_state.current_chat_id = None
        st.rerun()
    
    st.markdown("---")
    
    if chats_data:
        chat_ids = list(chats_data.keys())[::-1]
        for chat_id in chat_ids:
            chat_info = chats_data[chat_id]
            title = chat_info.get('title', 'Untitled')
            # æç®€æŒ‰é’®
            if st.button(title, key=chat_id, use_container_width=True):
                st.session_state.current_chat_id = chat_id
                st.rerun()
    else:
        st.caption("No history")

    st.markdown("---")
    with st.expander("System Prompts"):
        new_role_name = st.text_input("Name")
        new_role_prompt = st.text_area("Instructions")
        if st.button("Save"):
            if new_role_name and new_role_prompt:
                roles_data[new_role_name] = new_role_prompt
                save_data("roles.json", roles_data, roles_sha)
                st.rerun()

# --- ä¸»ç•Œé¢ ---

# åœºæ™¯ A: æ–°å»ºé¡µ (æç®€)
if st.session_state.current_chat_id is None:
    st.markdown("### Welcome back")
    
    if not roles_data:
        st.info("Please create a system prompt in the sidebar.")
    else:
        with st.container(border=True):
            c1, c2 = st.columns([1,1])
            with c1:
                selected_role = st.selectbox("System Prompt", list(roles_data.keys()))
            with c2:
                model_name = st.selectbox("Model", available_models)
            
            st.caption(f"Preview: {roles_data[selected_role][:80]}...")
            st.markdown("")
            
            if st.button("Run", type="primary"):
                new_id = str(uuid.uuid4())
                chats_data[new_id] = {
                    "title": "New Chat",
                    "role": selected_role,
                    "model": model_name,
                    "messages": []
                }
                save_data("chats.json", chats_data, chats_sha)
                st.session_state.current_chat_id = new_id
                st.rerun()

# åœºæ™¯ B: èŠå¤©é¡µ (æç®€)
else:
    chat_id = st.session_state.current_chat_id
    if chat_id not in chats_data:
        st.session_state.current_chat_id = None
        st.rerun()
        
    current_chat = chats_data[chat_id]
    role_name = current_chat.get("role", "Default")
    role_prompt = roles_data.get(role_name, "")
    messages = current_chat.get("messages", [])
    model_ver = current_chat.get("model", "gemini-1.5-pro")

    # é¡¶éƒ¨æç®€ä¿¡æ¯æ¡
    c1, c2, c3 = st.columns([6, 2, 1])
    with c1:
        st.markdown(f"**{role_name}** <span style='color:gray; font-size:12px'>via {model_ver}</span>", unsafe_allow_html=True)
    with c3:
        if st.button("Del", key="del"):
            del chats_data[chat_id]
            save_data("chats.json", chats_data, chats_sha)
            st.session_state.current_chat_id = None
            st.rerun()
    
    st.divider()

    # èŠå¤©æµ
    for msg in messages:
        # è‡ªå®šä¹‰å¤´åƒï¼šç”¨æˆ·ç”¨ç®€å•çš„åœ†ç‚¹ï¼ŒAIç”¨é—ªå…‰
        avatar = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ’ "
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

    # è¾“å…¥æ¡†
    if user_input := st.chat_input("Type a message..."):
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(user_input)
        
        messages.append({"role": "user", "content": user_input})
        if len(messages) == 1: current_chat["title"] = user_input[:15]
        
        try:
            model = genai.GenerativeModel(model_ver, system_instruction=role_prompt)
            history_gemini = [{"role": ("user" if m["role"]=="user" else "model"), "parts": [m["content"]]} for m in messages[:-1]]
            chat = model.start_chat(history=history_gemini)
            
            with st.chat_message("assistant", avatar="ğŸ’ "):
                placeholder = st.empty()
                full_response = ""
                stream = chat.send_message(user_input, stream=True)
                for chunk in stream:
                    if chunk.text:
                        full_response += chunk.text
                        placeholder.markdown(full_response + "â–Œ")
                placeholder.markdown(full_response)
            
            messages.append({"role": "assistant", "content": full_response})
            current_chat["messages"] = messages
            chats_data[chat_id] = current_chat
            save_data("chats.json", chats_data, chats_sha, message=f"Chat {chat_id}")
            
        except Exception as e:
            st.error(f"Error: {e}")
