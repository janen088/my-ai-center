import streamlit as st
import google.generativeai as genai
from github import Github
import json
import uuid
import time

# ================= 1. åŸºç¡€é…ç½® =================
st.set_page_config(page_title="æˆ‘çš„ AI Studio", page_icon="ğŸ§ ", layout="wide")

api_key = st.secrets.get("GEMINI_API_KEY")
github_token = st.secrets.get("GITHUB_TOKEN")
repo_name = st.secrets.get("REPO_NAME")

if not api_key or not github_token or not repo_name:
    st.error("âš ï¸ ç¼ºå°‘å¯†é’¥ï¼è¯·æ£€æŸ¥ Secrets")
    st.stop()

genai.configure(api_key=api_key)

# ================= 2. GitHub æ•°æ®åº“ (è¯»å†™è§’è‰² + è¯»å†™èŠå¤©è®°å½•) =================
def load_data(filename):
    """é€šç”¨è¯»å–å‡½æ•°"""
    try:
        g = Github(github_token)
        repo = g.get_repo(repo_name)
        try:
            contents = repo.get_contents(filename)
            return json.loads(contents.decoded_content.decode()), contents.sha
        except:
            return {}, None
    except:
        return {}, None

def save_data(filename, data, sha, message="Update"):
    """é€šç”¨ä¿å­˜å‡½æ•°"""
    try:
        g = Github(github_token)
        repo = g.get_repo(repo_name)
        content_str = json.dumps(data, indent=2, ensure_ascii=False)
        if sha:
            repo.update_file(filename, message, content_str, sha)
        else:
            repo.create_file(filename, "Init", content_str)
        return True
    except Exception as e:
        st.error(f"ä¿å­˜å¤±è´¥: {e}")
        return False

# ================= 3. é¡µé¢é€»è¾‘ =================

# --- åˆå§‹åŒ–æ•°æ® ---
if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = None

# è¯»å– GitHub ä¸Šçš„æ•°æ®
roles_data, roles_sha = load_data("roles.json")
chats_data, chats_sha = load_data("chats.json")

# --- ä¾§è¾¹æ ï¼šå†å²è®°å½•ä¸æ–°å»º ---
with st.sidebar:
    st.title("ğŸ—‚ï¸ å¯¹è¯åˆ—è¡¨")
    
    # æ–°å»ºå¯¹è¯æŒ‰é’®
    if st.button("â• æ–°å»ºå¯¹è¯", type="primary", use_container_width=True):
        st.session_state.current_chat_id = None # è®¾ä¸º None è¡¨ç¤ºè¿›å…¥æ–°å»ºé¡µé¢
        st.rerun()
    
    st.divider()
    
    # åˆ—å‡ºå†å²å¯¹è¯ (æŒ‰æ—¶é—´å€’åºï¼Œè¿™é‡Œç®€å•å¤„ç†)
    # chats_data ç»“æ„: { "uuid": { "title": "æ ‡é¢˜", "role": "è§’è‰²å", "messages": [...] } }
    if chats_data:
        for chat_id, chat_info in list(chats_data.items())[::-1]:
            label = f"ğŸ“ {chat_info.get('title', 'æœªå‘½åå¯¹è¯')}"
            if st.button(label, key=chat_id, use_container_width=True):
                st.session_state.current_chat_id = chat_id
                st.rerun()
    else:
        st.caption("æš‚æ— å†å²è®°å½•")

    st.divider()
    # åº•éƒ¨ï¼šè§’è‰²ç®¡ç†å…¥å£
    with st.expander("âš™ï¸ è§’è‰²åº“ç®¡ç†"):
        new_role_name = st.text_input("æ–°è§’è‰²å")
        new_role_prompt = st.text_area("è®¾å®šå†…å®¹")
        if st.button("ä¿å­˜æ–°è§’è‰²"):
            if new_role_name and new_role_prompt:
                roles_data[new_role_name] = new_role_prompt
                save_data("roles.json", roles_data, roles_sha)
                st.success("å·²ä¿å­˜")
                st.rerun()

# --- ä¸»ç•Œé¢åŒºåŸŸ ---

# åœºæ™¯ A: æ–°å»ºå¯¹è¯å‘å¯¼
if st.session_state.current_chat_id is None:
    st.header("âœ¨ å¼€å¯ä¸€ä¸ªæ–°çš„ä¼šè¯")
    
    if not roles_data:
        st.warning("è¯·å…ˆåœ¨å·¦ä¸‹è§’ã€âš™ï¸ è§’è‰²åº“ç®¡ç†ã€‘ä¸­æ·»åŠ ä¸€ä¸ªè§’è‰²ï¼")
    else:
        # 1. é€‰è§’è‰²
        selected_role = st.selectbox("é€‰æ‹©ä¸€ä½ AI ä¼™ä¼´ï¼š", list(roles_data.keys()))
        st.info(f"å½“å‰è®¾å®šï¼š{roles_data[selected_role]}")
        
        # 2. é€‰æ¨¡å‹
        model_name = st.selectbox("é€‰æ‹©å¤§è„‘ï¼š", ["gemini-1.5-pro", "gemini-2.0-flash-exp", "gemini-2.0-flash-thinking-exp-1219"])
        
        # 3. å¼€å§‹æŒ‰é’®
        if st.button("å¼€å§‹èŠå¤© ğŸš€"):
            # ç”Ÿæˆæ–° ID
            new_id = str(uuid.uuid4())
            # åˆå§‹åŒ–æ•°æ®ç»“æ„
            chats_data[new_id] = {
                "title": "æ–°å¯¹è¯",
                "role": selected_role,
                "model": model_name,
                "messages": []
            }
            # ä¿å­˜åˆ° GitHub
            save_data("chats.json", chats_data, chats_sha)
            # åˆ‡æ¢çŠ¶æ€
            st.session_state.current_chat_id = new_id
            st.rerun()

# åœºæ™¯ B: èŠå¤©ç•Œé¢ (ç±»ä¼¼ AI Studio)
else:
    chat_id = st.session_state.current_chat_id
    
    # å®¹é”™ï¼šå¦‚æœ ID ä¸åœ¨æ•°æ®é‡Œï¼ˆæ¯”å¦‚åˆšåˆ äº†ï¼‰
    if chat_id not in chats_data:
        st.session_state.current_chat_id = None
        st.rerun()
        
    current_chat = chats_data[chat_id]
    role_name = current_chat.get("role", "é»˜è®¤")
    role_prompt = roles_data.get(role_name, "") # è·å–æœ€æ–°çš„è§’è‰²è®¾å®š
    messages = current_chat.get("messages", [])
    model_ver = current_chat.get("model", "gemini-1.5-pro")

    # æ ‡é¢˜æ 
    col1, col2 = st.columns([5, 1])
    with col1:
        st.subheader(f"æ­£åœ¨ä¸ã€{role_name}ã€‘å¯¹è¯")
    with col2:
        if st.button("ğŸ—‘ï¸ åˆ é™¤", type="primary"):
            del chats_data[chat_id]
            save_data("chats.json", chats_data, chats_sha)
            st.session_state.current_chat_id = None
            st.rerun()

    # æ˜¾ç¤ºèŠå¤©è®°å½•
    for msg in messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # è¾“å…¥æ¡†
    if user_input := st.chat_input("ç»§ç»­è¿½é—®..."):
        # 1. æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # æ›´æ–°æœ¬åœ°æ•°æ®
        messages.append({"role": "user", "content": user_input})
        
        # å¦‚æœæ˜¯ç¬¬ä¸€å¥è¯ï¼Œè‡ªåŠ¨æ›´æ–°æ ‡é¢˜
        if len(messages) == 1:
            current_chat["title"] = user_input[:10] + "..."

        # 2. è°ƒç”¨ AI
        try:
            # æ„é€ å¸¦ System Prompt çš„å†å²
            # Gemini API çš„ system_instruction å‚æ•°æœ€å¥½åœ¨ model åˆå§‹åŒ–æ—¶ä¼ å…¥ï¼Œæˆ–è€…æ‹¼åœ¨ç¬¬ä¸€æ¡
            # è¿™é‡Œæˆ‘ä»¬ç”¨æœ€ç¨³å¦¥çš„æ–¹å¼ï¼šæ‹¼åœ¨ history çš„æœ€å‰é¢ï¼Œæˆ–è€…ä½œä¸º system_instruction
            
            model = genai.GenerativeModel(
                model_ver,
                system_instruction=role_prompt # å…³é”®ï¼šè®©å®ƒæ°¸è¿œè®°å¾—è®¾å®š
            )
            
            # è½¬æ¢å†å²æ ¼å¼
            history_gemini = []
            for m in messages[:-1]: # ä¸åŒ…å«æœ€æ–°è¿™æ¡ï¼Œå› ä¸º send_message ä¼šå‘
                role = "user" if m["role"] == "user" else "model"
                history_gemini.append({"role": role, "parts": [m["content"]]})
            
            chat = model.start_chat(history=history_gemini)
            
            # æµå¼è¾“å‡º
            with st.chat_message("assistant"):
                placeholder = st.empty()
                full_response = ""
                stream = chat.send_message(user_input, stream=True)
                
                for chunk in stream:
                    if chunk.text:
                        full_response += chunk.text
                        placeholder.markdown(full_response + "â–Œ")
                placeholder.markdown(full_response)
            
            # 3. ä¿å­˜ AI å›å¤
            messages.append({"role": "assistant", "content": full_response})
            
            # 4. åŒæ­¥å› GitHub (æŒä¹…åŒ–ä¿å­˜ï¼)
            # æ›´æ–°å†…å­˜æ•°æ®
            current_chat["messages"] = messages
            chats_data[chat_id] = current_chat
            
            # æ˜¾ç¤ºä¿å­˜çŠ¶æ€
            with st.status("æ­£åœ¨ä¿å­˜è®°å¿†...", expanded=False) as status:
                save_data("chats.json", chats_data, chats_sha, message=f"Chat {chat_id}")
                status.update(label="è®°å¿†å·²åŒæ­¥åˆ°äº‘ç«¯", state="complete", expanded=False)
            
        except Exception as e:
            st.error(f"å‡ºé”™: {e}")
